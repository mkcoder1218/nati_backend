/**
 * Alternative script to export the PostgreSQL database schema and data for migration to Supabase
 * using pure JavaScript (no pg_dump required)
 * 
 * This script:
 * 1. Connects to the database using the pg library
 * 2. Extracts table schemas and data
 * 3. Generates SQL files for import to Supabase
 */

require('dotenv').config();
const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');

// Create exports directory if it doesn't exist
const exportsDir = path.join(__dirname, 'exports');
if (!fs.existsSync(exportsDir)) {
  fs.mkdirSync(exportsDir);
}

// Database connection details from .env
const dbHost = process.env.DB_HOST || 'localhost';
const dbPort = process.env.DB_PORT || '5432';
const dbName = process.env.DB_NAME || 'government_feedback';
const dbUser = process.env.DB_USER || 'postgres';
const dbPassword = process.env.DB_PASSWORD || 'postgres';

// Create a connection pool
const pool = new Pool({
  host: dbHost,
  port: dbPort,
  database: dbName,
  user: dbUser,
  password: dbPassword,
});

// Files to write
const schemaFile = path.join(exportsDir, 'schema.sql');
const dataFile = path.join(exportsDir, 'data.sql');
const combinedFile = path.join(exportsDir, 'full_export.sql');

// Initialize files
fs.writeFileSync(schemaFile, '-- Schema export generated by export-database-js.js\n\n');
fs.writeFileSync(dataFile, '-- Data export generated by export-database-js.js\n\n');

async function exportDatabase() {
  let client;
  
  try {
    console.log('Connecting to PostgreSQL...');
    client = await pool.connect();
    console.log('Connected successfully!');
    
    // Get all tables in the public schema
    console.log('Getting list of tables...');
    const tablesResult = await client.query(`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public'
      ORDER BY table_name
    `);
    
    if (tablesResult.rows.length === 0) {
      console.error('No tables found in the database.');
      return;
    }
    
    console.log(`Found ${tablesResult.rows.length} tables.`);
    
    // Get all enum types
    console.log('Getting enum types...');
    const enumsResult = await client.query(`
      SELECT t.typname AS enum_name,
             e.enumlabel AS enum_value
      FROM pg_type t
      JOIN pg_enum e ON t.oid = e.enumtypid
      JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
      WHERE n.nspname = 'public'
      ORDER BY t.typname, e.enumsortorder
    `);
    
    // Generate CREATE TYPE statements for enums
    if (enumsResult.rows.length > 0) {
      console.log('Exporting enum types...');
      
      let currentEnum = '';
      let enumValues = [];
      
      // Append to schema file
      fs.appendFileSync(schemaFile, '-- Enum types\n');
      
      enumsResult.rows.forEach(row => {
        if (currentEnum !== row.enum_name) {
          // Write the previous enum if it exists
          if (currentEnum !== '') {
            const enumSql = `CREATE TYPE ${currentEnum} AS ENUM (${enumValues.map(v => `'${v}'`).join(', ')});\n\n`;
            fs.appendFileSync(schemaFile, enumSql);
          }
          
          // Start a new enum
          currentEnum = row.enum_name;
          enumValues = [row.enum_value];
        } else {
          // Add value to current enum
          enumValues.push(row.enum_value);
        }
      });
      
      // Write the last enum
      if (currentEnum !== '') {
        const enumSql = `CREATE TYPE ${currentEnum} AS ENUM (${enumValues.map(v => `'${v}'`).join(', ')});\n\n`;
        fs.appendFileSync(schemaFile, enumSql);
      }
    }
    
    // Process each table
    for (const tableRow of tablesResult.rows) {
      const tableName = tableRow.table_name;
      console.log(`Processing table: ${tableName}`);
      
      // Get table schema
      const tableSchemaResult = await client.query(`
        SELECT column_name, data_type, character_maximum_length, 
               is_nullable, column_default, udt_name
        FROM information_schema.columns
        WHERE table_schema = 'public' AND table_name = $1
        ORDER BY ordinal_position
      `, [tableName]);
      
      // Get primary key
      const pkResult = await client.query(`
        SELECT a.attname
        FROM pg_index i
        JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)
        WHERE i.indrelid = $1::regclass AND i.indisprimary
      `, [tableName]);
      
      // Get foreign keys
      const fkResult = await client.query(`
        SELECT
          kcu.column_name,
          ccu.table_name AS foreign_table_name,
          ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
          ON tc.constraint_name = kcu.constraint_name
          AND tc.table_schema = kcu.table_schema
        JOIN information_schema.constraint_column_usage AS ccu
          ON ccu.constraint_name = tc.constraint_name
          AND ccu.table_schema = tc.table_schema
        WHERE tc.constraint_type = 'FOREIGN KEY'
          AND tc.table_name = $1
      `, [tableName]);
      
      // Generate CREATE TABLE statement
      let createTableSql = `CREATE TABLE ${tableName} (\n`;
      
      // Add columns
      tableSchemaResult.rows.forEach((column, index) => {
        let columnDef = `  ${column.column_name} `;
        
        // Handle data type
        if (column.udt_name && ['_varchar', '_text', '_int4', '_int8', '_float8', '_bool'].includes(column.udt_name)) {
          // Array type
          const baseType = column.udt_name.replace('_', '');
          let typeName;
          
          switch (baseType) {
            case 'varchar': typeName = 'VARCHAR'; break;
            case 'text': typeName = 'TEXT'; break;
            case 'int4': typeName = 'INTEGER'; break;
            case 'int8': typeName = 'BIGINT'; break;
            case 'float8': typeName = 'DOUBLE PRECISION'; break;
            case 'bool': typeName = 'BOOLEAN'; break;
            default: typeName = baseType.toUpperCase();
          }
          
          columnDef += `${typeName}[]`;
        } else if (column.data_type === 'USER-DEFINED') {
          // Enum or custom type
          columnDef += column.udt_name;
        } else if (column.data_type === 'character varying') {
          // VARCHAR with length
          columnDef += `VARCHAR(${column.character_maximum_length})`;
        } else {
          // Standard type
          columnDef += column.data_type.toUpperCase();
        }
        
        // Nullable
        if (column.is_nullable === 'NO') {
          columnDef += ' NOT NULL';
        }
        
        // Default value
        if (column.column_default) {
          columnDef += ` DEFAULT ${column.column_default}`;
        }
        
        // Add comma if not the last column
        if (index < tableSchemaResult.rows.length - 1 || pkResult.rows.length > 0 || fkResult.rows.length > 0) {
          columnDef += ',';
        }
        
        createTableSql += columnDef + '\n';
      });
      
      // Add primary key
      if (pkResult.rows.length > 0) {
        const pkColumns = pkResult.rows.map(row => row.attname).join(', ');
        createTableSql += `  PRIMARY KEY (${pkColumns})`;
        
        // Add comma if there are foreign keys
        if (fkResult.rows.length > 0) {
          createTableSql += ',';
        }
        
        createTableSql += '\n';
      }
      
      // Add foreign keys
      fkResult.rows.forEach((fk, index) => {
        createTableSql += `  FOREIGN KEY (${fk.column_name}) REFERENCES ${fk.foreign_table_name}(${fk.foreign_column_name})`;
        
        // Add comma if not the last foreign key
        if (index < fkResult.rows.length - 1) {
          createTableSql += ',';
        }
        
        createTableSql += '\n';
      });
      
      createTableSql += ');\n\n';
      
      // Append to schema file
      fs.appendFileSync(schemaFile, createTableSql);
      
      // Get table data
      const dataResult = await client.query(`SELECT * FROM ${tableName}`);
      
      if (dataResult.rows.length > 0) {
        console.log(`Exporting data for table ${tableName} (${dataResult.rows.length} rows)`);
        
        // Generate INSERT statements
        fs.appendFileSync(dataFile, `-- Data for table ${tableName}\n`);
        
        for (const row of dataResult.rows) {
          const columns = Object.keys(row).join(', ');
          const values = Object.values(row).map(value => {
            if (value === null) return 'NULL';
            if (typeof value === 'string') return `'${value.replace(/'/g, "''")}'`;
            if (typeof value === 'object') {
              if (value instanceof Date) return `'${value.toISOString()}'`;
              return `'${JSON.stringify(value).replace(/'/g, "''")}'`;
            }
            return value;
          }).join(', ');
          
          const insertSql = `INSERT INTO ${tableName} (${columns}) VALUES (${values});\n`;
          fs.appendFileSync(dataFile, insertSql);
        }
        
        fs.appendFileSync(dataFile, '\n');
      }
    }
    
    // Create combined file
    console.log('Creating combined export file...');
    const schemaContent = fs.readFileSync(schemaFile, 'utf8');
    const dataContent = fs.readFileSync(dataFile, 'utf8');
    fs.writeFileSync(combinedFile, `${schemaContent}\n${dataContent}`);
    
    console.log('\nExport completed successfully!');
    console.log(`Schema exported to ${schemaFile}`);
    console.log(`Data exported to ${dataFile}`);
    console.log(`Combined export saved to ${combinedFile}`);
    
    console.log('\nNext steps:');
    console.log('1. Import the schema and data to Supabase');
    console.log('2. Update your application\'s database connection settings');
    
  } catch (error) {
    console.error('Error exporting database:', error.message);
  } finally {
    if (client) {
      client.release();
    }
    await pool.end();
  }
}

exportDatabase();
